/-
Copyright (c) 2023 Wanyi He. All rights reserved.
Released under Apache 2.0 license as described in the file LICENSE.
Author: Wanyi He
-/
import Mathlib.Analysis.InnerProductSpace.PiL2
import Mathlib.Topology.MetricSpace.Basic
import Mathlib.Topology.Basic
import Mathlib.Analysis.Convex.Function
import Analysis.Basic
import Mathlib.Topology.MetricSpace.PseudoMetric
import Function.Convex_Function

/-!
# Subgradient of convex functions in EuclideanSpace

The file defines subgradient for convex functions in E and proves some basic properties.

Let `f : E ‚Üí ‚Ñù` be a convex function on `s` and `g : E`,
where `s` is a set of `E`. Suppose `hf : ConvexOn ‚Ñù s f`.
`g` is a subgradient of `f` at `x` if for any `y ‚àà s`, we have `f y ‚â• f x + inner g (y - x)`.
The insight comes from the first order condition of convex function.

## Main declarations

* `IsSubgradAt hf g x`: The convex function `f` has subgradient `g` at `x`.
Here `f` is given as an implicit argument
* `SubderivAt hf x`: The collection of all possible subgradients of `f` at `x`.

## Main results

* `subgrad_of_grad` : If `f` has Fderiv `f' x` at `x`, then `SubderivAt hf x = {grad (f' x)}`.
* `zero_mem_iff_isGlobalmin` : Optimality conditions for convex objective functions
-/

open Filter Topology Set InnerProductSpace


noncomputable section

variable {n : Type _} [Fintype n] [DecidableEq n]

variable {E : Type*} [NormedAddCommGroup E] [InnerProductSpace ‚Ñù E] [CompleteSpace E]

variable {s : Set E}

variable {f : E ‚Üí ‚Ñù} {g : E} {x : E}

variable {f' : E ‚Üí (E ‚ÜíL[‚Ñù] ‚Ñù)}

set_option quotPrecheck false

local notation gradient "‚àá*" => (toDualMap ‚Ñù _) gradient

local notation "‚ü™" x ", " y "‚ü´" => @inner ‚Ñù _ _ x y

/-- Subgradient of functions --/
def IsSubgradAt (_ : ConvexOn ‚Ñù s f) (g x : E) : Prop :=
  ‚àÄ y ‚àà s, f y ‚â• f x + inner g (y - x)

/-- Subderiv of functions --/
def SubderivAt (hf : ConvexOn ‚Ñù s f) (x :  E) : Set E :=
  {g : E| IsSubgradAt hf g x}

@[simp]
theorem mem_SubderivAt (hf : ConvexOn ‚Ñù s f) : IsSubgradAt hf g x ‚Üî g ‚àà SubderivAt hf x := ‚ü®id, id‚ü©

/-! ### Basic properties about `Subderiv` -/

open EuclideanSpace Set

variable (hf : ConvexOn ‚Ñù s f)

/-- The subderiv of `f` at `x` is a closed set. --/
theorem Subderiv.isClosed : ‚àÄ x ‚àà s, IsClosed (SubderivAt hf x) := by
  intro x _
  by_cases e : SubderivAt hf x = ‚àÖ
  ¬∑ apply Eq.subst (Eq.symm e) isClosed_empty
  rw [‚Üê isSeqClosed_iff_isClosed]
  intro g g' hg cg y ys
  obtain cg' := Tendsto.const_add (f x) (Filter.Tendsto.inner cg tendsto_const_nhds)
  apply le_of_tendsto_of_tendsto' cg' tendsto_const_nhds (fun n => hg n y ys)

/-- The subderiv of `f` at `x` is a convex set. --/
theorem Subderiv.convex : ‚àÄ x ‚àà s, Convex ‚Ñù (SubderivAt hf x) := by
  intro x _
  by_cases e : SubderivAt hf x = ‚àÖ
  ¬∑ apply Eq.subst (Eq.symm e) convex_empty
  intro g‚ÇÅ h1 g‚ÇÇ h2 a b lea leb abeq y ys
  have ineq1 : a ‚Ä¢ f y ‚â• a ‚Ä¢ f x + a ‚Ä¢ ‚ü™g‚ÇÅ, y - x‚ü´ := by
    rw [‚Üê smul_add]
    apply smul_le_smul_of_nonneg (h1 y ys) lea
  have ineq2 : b ‚Ä¢ f y ‚â• b ‚Ä¢ f x + b ‚Ä¢ inner g‚ÇÇ (y - x) := by
    rw [‚Üê smul_add]
    apply smul_le_smul_of_nonneg (h2 y ys) leb
  have eq : (a ‚Ä¢ f x + a ‚Ä¢ inner g‚ÇÅ (y - x)) + (b ‚Ä¢ f x + b ‚Ä¢ inner g‚ÇÇ (y - x))
      = f x + inner (a ‚Ä¢ g‚ÇÅ + b ‚Ä¢ g‚ÇÇ) (y - x) := by
    rw [add_add_add_comm, ‚Üê Eq.symm (Convex.combo_self abeq (f x))]
    apply congrArg (HAdd.hAdd (f x))
    rw [inner_add_left, inner_smul_left, inner_smul_left]; rfl
  rw [Eq.symm (Convex.combo_self abeq (f y)), ‚Üê eq]
  apply add_le_add ineq1 ineq2


/-- Monotonicity of subderiv--/
theorem subgrad_mono {u v : E} (hf : ConvexOn ‚Ñù s f) (xs : x ‚àà s) (ys : y ‚àà s)
  (hu : u ‚àà SubderivAt hf x) (hv : v ‚àà SubderivAt hf y) :
    ‚ü™u - v, x - y‚ü´ ‚â• (0 : ‚Ñù):= by
      specialize hu y ys; specialize hv x xs
      have ineq1 : ‚ü™u, x - y‚ü´ ‚â• f x - f y := by
        rw [congrArg (inner u) (Eq.symm (neg_sub y x)), inner_neg_right]; linarith
      have ineq2 := Iff.mpr le_sub_iff_add_le' hv
      rw [inner_sub_left]; linarith


/-! ### Calculation of `Subderiv` -/

open Pointwise

lemma first_order_condition_gradn {f: E ‚Üí ‚Ñù} {gradf : E}
  {s : Set E} {x: E} (h: HasGradientAt f gradf x) (hf: ConvexOn ‚Ñù s f) (xs: x‚àà s) :
  ‚àÄ (y : E), y ‚àà s ‚Üí f x + inner gradf (y - x) ‚â§ f y:= by
  have H1: ‚àÄ (y : E), y ‚àà s ‚Üí f x + (gradf ‚àá*) (y - x) ‚â§ f y:= by
    rw [HasGradientAt] at h
    apply first_order_condition; apply h;
    apply hf; apply xs
  intro y ys
  specialize H1 y ys
  exact H1

/-- Subderiv of differentiable functions --/
theorem subgrad_of_grad' (hx : x ‚àà interior s) (hf : ConvexOn ‚Ñù s f) (h : HasGradientAt f g x) :
  SubderivAt hf x = {g} := by
  obtain h' := HasGradientAt_iff_HasFDerivAt.mp h
  rw [Set.eq_singleton_iff_nonempty_unique_mem]
  constructor
  ¬∑ use g; intro y ys
    exact first_order_condition_gradn h hf (interior_subset hx) y ys
  intro g' hg'; by_contra neq
  apply not_le_of_lt (norm_sub_pos_iff.mpr neq)
  let v := g' - g; obtain vneq := sub_ne_zero.mpr neq
  have : Tendsto (fun (t : ‚Ñù) => (f (x + t ‚Ä¢ v) - f x - ‚ü™g, t ‚Ä¢ v‚ü´) * ‚Äñt ‚Ä¢ v‚Äñ‚Åª¬π) (ùìù[>] 0) (ùìù 0) := by
    rw [Metric.tendsto_nhdsWithin_nhds]; intro Œµ Œµpos
    unfold HasFDerivAt at h'
    rw [hasFDerivAtFilter_iff_tendsto, Metric.tendsto_nhds_nhds] at h'
    obtain ‚ü®Œ¥, Œ¥pos, hŒ¥‚ü© := h' Œµ Œµpos
    use (Œ¥ * ‚Äñv‚Äñ‚Åª¬π)
    obtain pos := mul_pos Œ¥pos (inv_pos.mpr (norm_pos_iff.mpr vneq))
    constructor
    ¬∑ exact pos
    intro t _ ht; rw [dist_eq_norm] at ht; rw [dist_eq_norm]
    have : dist (x + t ‚Ä¢ v) x < Œ¥ := by
      rw [dist_eq_norm, add_sub_cancel', norm_smul, ‚Üê (sub_zero t)]
      apply lt_of_lt_of_eq ((mul_lt_mul_right (norm_sub_pos_iff.mpr neq)).mpr ht)
      rw [mul_assoc, inv_mul_cancel (norm_ne_zero_iff.mpr vneq), mul_one]
    specialize hŒ¥ this; rw [dist_eq_norm] at hŒ¥
    have eq1 : ‚Äñ‚Äñx + t ‚Ä¢ v - x‚Äñ‚Åª¬π‚Äñ = ‚Äñt ‚Ä¢ v‚Äñ‚Åª¬π := by
      rw [add_sub_cancel', norm_inv, norm_norm]
    have eq2 : (g ‚àá*) (x + t ‚Ä¢ v - x) = ‚ü™g, t ‚Ä¢ v‚ü´ := by rw [add_sub_cancel']; exact rfl
    have eq3 : ‚Äñ(f (x + t ‚Ä¢ v) - f x - ‚ü™g, t ‚Ä¢ v‚ü´) * ‚Äñt ‚Ä¢ v‚Äñ‚Åª¬π - 0‚Äñ =
      ‚Äñf (x + t ‚Ä¢ v) - f x - ‚ü™g, t ‚Ä¢ v‚ü´‚Äñ * ‚Äñt ‚Ä¢ v‚Äñ‚Åª¬π := by
        rw [sub_zero, norm_mul, norm_inv, norm_norm]
    have eq : ‚Äñ‚Äñx + t ‚Ä¢ v - x‚Äñ‚Åª¬π * ‚Äñf (x + t ‚Ä¢ v) - f x - (g ‚àá*) (x + t ‚Ä¢ v - x)‚Äñ - 0‚Äñ =
      ‚Äñ(f (x + t ‚Ä¢ v) - f x - ‚ü™g, t ‚Ä¢ v‚ü´) * ‚Äñt ‚Ä¢ v‚Äñ‚Åª¬π - 0‚Äñ := by
        rw [sub_zero, norm_mul, norm_norm, mul_comm, eq1, eq2, ‚Üê eq3]
    apply Eq.trans_lt (Eq.symm eq) hŒ¥
  apply ge_of_tendsto this
  rw [Filter.Eventually, Metric.mem_nhdsWithin_iff]
  rw [mem_interior_iff_mem_nhds, Metric.mem_nhds_iff] at hx
  obtain ‚ü®Œµ, Œµpos, ballmem‚ü© := hx
  obtain pos := mul_pos Œµpos (inv_pos.mpr (norm_pos_iff.mpr vneq))
  use (Œµ * ‚Äñv‚Äñ‚Åª¬π); use pos; intro t ht
  have tball := ht.1; have tlt : t > 0 := ht.2
  have tvpos : ‚Äñt ‚Ä¢ v‚Äñ‚Åª¬π > 0 := by
    apply inv_pos.mpr; rw [norm_smul]
    apply smul_pos (abs_pos_of_pos tlt) (norm_sub_pos_iff.mpr neq)
  have mems : x + t ‚Ä¢ v ‚àà s := by
    apply ballmem
    rw [mem_ball_iff_norm, sub_zero] at tball
    rw [mem_ball_iff_norm, add_sub_cancel', norm_smul]
    have : ‚Äñt‚Äñ * ‚Äñv‚Äñ < Œµ * ‚Äñv‚Äñ‚Åª¬π * ‚Äñv‚Äñ := by
      apply (mul_lt_mul_right (norm_sub_pos_iff.mpr neq)).mpr tball
    rwa [mul_assoc, inv_mul_cancel (norm_ne_zero_iff.mpr vneq), mul_one] at this
  obtain ineq1 := hg' (x + t ‚Ä¢ v) mems; rw [add_sub_cancel'] at ineq1
  have eq1 : ‚Äñv‚Äñ = (‚ü™g', t ‚Ä¢ v‚ü´ - ‚ü™g, t ‚Ä¢ v‚ü´) * ‚Äñt ‚Ä¢ v‚Äñ‚Åª¬π := by
    have eq2 : ‚Äñv‚Äñ = ‚ü™v, v‚ü´ * ‚Äñv‚Äñ‚Åª¬π := by
      rw [real_inner_self_eq_norm_sq]
      apply (div_eq_iff _).mp
      ¬∑ rw [div_inv_eq_mul, pow_two]
      exact inv_ne_zero (norm_ne_zero_iff.mpr vneq)
    have eq3 : ‚ü™v, v‚ü´ * ‚Äñv‚Äñ‚Åª¬π = ‚ü™v, t ‚Ä¢ v‚ü´ * ‚Äñt ‚Ä¢ v‚Äñ‚Åª¬π := by
      have : ‚ü™v, t ‚Ä¢ v‚ü´ = ‚ü™v, v‚ü´ * t := by rw [inner_smul_right, mul_comm]
      rw [this, mul_assoc]
      have : ‚Äñv‚Äñ‚Åª¬π = t * ‚Äñt ‚Ä¢ v‚Äñ‚Åª¬π := by
        have :  t * ‚Äñt ‚Ä¢ v‚Äñ‚Åª¬π = t / ‚Äñt ‚Ä¢ v‚Äñ := rfl
        rw [this, inv_eq_one_div]
        have : t = ‚Äñt‚Äñ := by
          have : ‚Äñt‚Äñ = |t| := rfl
          rw [this, abs_of_pos tlt]
        rw [this, norm_smul, norm_norm, div_mul_eq_div_div, div_self]
        rw [norm_ne_zero_iff]
        exact ne_of_gt tlt
      rw [this]
    rw [eq2, eq3, mul_eq_mul_right_iff];
    left; rw [inner_sub_left]
  rw [mem_setOf, eq1, mul_le_mul_right tvpos]
  apply sub_le_sub_right (le_sub_iff_add_le'.mpr ineq1)

/-- Alternarive version for FDeriv --/
theorem subgrad_of_grad (hx : x ‚àà interior s) (hf : ConvexOn ‚Ñù s f) (h : HasFDerivAt f (f' x) x) :
  SubderivAt hf x = {(toDual ‚Ñù E).symm (f' x)} := by
    have h‚ÇÅ : HasFDerivAt f ((toDual ‚Ñù E) ((LinearIsometryEquiv.symm (toDual ‚Ñù E)) (f' x))) x := by
      simp [h]
    obtain h' := HasGradientAt_iff_HasFDerivAt.mpr h‚ÇÅ
    exact subgrad_of_grad' hx hf h'

/-- Subderiv of the sum of two functions is a subset of the sum of the subderivs of the two functions --/
theorem subgrad_of_add {s t : Set E} {f‚ÇÅ f‚ÇÇ : E ‚Üí ‚Ñù}
  (hf‚ÇÅ : ConvexOn ‚Ñù s f‚ÇÅ) (hf‚ÇÇ : ConvexOn ‚Ñù t f‚ÇÇ) (hadd : ConvexOn ‚Ñù (s ‚à© t) (f‚ÇÅ + f‚ÇÇ)):
    ‚àÄ (x : E), SubderivAt hf‚ÇÅ x + SubderivAt hf‚ÇÇ x ‚äÜ SubderivAt hadd x := by
      intro x y ymem; intro y' hy'
      obtain ‚ü®y‚ÇÅ, y‚ÇÇ, hy‚ÇÅ, hy‚ÇÇ, eq‚ü© := Set.mem_add.mpr ymem
      have eq' : y‚ÇÅ + y‚ÇÇ = y := eq
      have : (f‚ÇÅ + f‚ÇÇ) y' ‚â• (f‚ÇÅ x + ‚ü™y‚ÇÅ, y' - x‚ü´) + (f‚ÇÇ x + ‚ü™y‚ÇÇ, y' - x‚ü´ ):= add_le_add (hy‚ÇÅ y' hy'.1) (hy‚ÇÇ y' hy'.2)
      rwa [add_add_add_comm, ‚Üê inner_add_left, eq'] at this


/-! ### Optimality Theory for Unconstrained Nondifferentiable Problems -/

theorem zero_mem (hf : ConvexOn ‚Ñù s f) (h : x ‚àà {x | ‚àÄ y ‚àà s, f x ‚â§ f y}) :
  (0 : E) ‚àà SubderivAt hf x :=
    fun y ys => le_of_le_of_eq' (h y ys) (by rw [inner_zero_left, add_zero])

theorem isGlobalmin (hf : ConvexOn ‚Ñù s f) (h : (0 : E) ‚àà SubderivAt hf x ) :
  x ‚àà {x | ‚àÄ y ‚àà s, f x ‚â§ f y} := by
    intro y ys; specialize h y ys
    rwa [inner_zero_left, add_zero] at h

/-- `x'` minimize `f` if and only if `0` is a subgradient of `f` at `x'` --/
theorem zero_mem_iff_isGlobalmin (hf : ConvexOn ‚Ñù s f) :
  (0 : E) ‚àà SubderivAt hf x ‚Üî x ‚àà {x | ‚àÄ y ‚àà s, f x ‚â§ f y} :=
    ‚ü®fun h => isGlobalmin hf h, fun h => zero_mem hf h‚ü©



/-! ### Convergence of Subgradient method -/
variable {G : NNReal} (hf : ConvexOn ‚Ñù s f) (lf : LipschitzWith G f)

variable (point : ‚Ñï ‚Üí E) (g : ‚Ñï ‚Üí E)
  (a : ‚Ñï ‚Üí ‚Ñù) (ha : ‚àÄ (n : ‚Ñï), a n > 0) (x‚ÇÄ : E)
  (hg : ‚àÄ (n : ‚Ñï), g n ‚àà SubderivAt hf (point n))

variable (update : ‚àÄ (k : ‚Ñï), (point (k + 1)) = point k - a k ‚Ä¢ (g k))

variable (xm : E) (hm : IsMinOn f s xm)

/- Subgradient of `f` is bounded if and only if `f` is Lipschitz -/
theorem bounded_subgradient_iff_Lipschitz :
    ‚àÄ g ‚àà SubderivAt hf x, ‚Äñg‚Äñ ‚â§ G ‚Üî LipschitzWith G f := by sorry

theorem subgradient_method :
    ‚àÄ (k : ‚Ñï), 2 * ((Finset.range (k + 1)).sum a) * (sInf {f (point i) | i ‚àà Finset.range (k + 1)} - (f xm))
      ‚â§ ‚Äñx‚ÇÄ - xm‚Äñ ^ 2 + G ^ 2 * (Finset.range (k + 1)).sum (fun i => (a i) ^ 2) := by sorry

theorem subgradient_method_1 {t : ‚Ñù} (ha' : ‚àÄ (n : ‚Ñï), a n = t) :
    ‚àÄ (k : ‚Ñï), sInf {f (point i) | i ‚àà Finset.range (k + 1)} - (f xm)
      ‚â§ ‚Äñx‚ÇÄ - xm‚Äñ ^ 2 / (2 * k * t) + G ^ 2 * t / 2 := by sorry

theorem subgradient_method_2 {s : ‚Ñù} (ha' : ‚àÄ (n : ‚Ñï), a n * ‚Äñg n‚Äñ = s) :
    ‚àÄ (k : ‚Ñï), sInf {f (point i) | i ‚àà Finset.range (k + 1)} - (f xm)
      ‚â§ G * ‚Äñx‚ÇÄ - xm‚Äñ ^ 2 / (2 * k * s) + G * s / 2 := by sorry

theorem subgradient_method_3 (ha' : Tendsto a atTop (ùìù 0))
    (ha'' : Tendsto (fun (k : ‚Ñï) => (Finset.range (k + 1)).sum a) atTop atTop) :
    Tendsto (fun k => sInf {f (point i) | i ‚àà Finset.range (k + 1)}) atTop (ùìù (f xm)) := by sorry

end
